{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2607a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI client with the base URL and API key\n",
    "client = OpenAI(\n",
    "    #base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # Retrieve the API key from environment variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0ad8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdfs_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            with fitz.open(pdf_path) as doc:\n",
    "                text = \"\"\n",
    "                for page in doc:\n",
    "                    text += page.get_text()  # Extracts all visible text per page\n",
    "                documents.append(text)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130f3d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 PDFs loaded and extracted.\n",
      "Preview of first document:\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "Improving Public Messaging \n",
      "for Evacuation and Shelter‐in‐Place \n",
      "Findings and Recommendations for Emergency Managers\n",
      "from Peer-Reviewed Research \n",
      "April 2021 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Improving Public Messaging for Evacuation and Shelter-in-Place \n",
      "This page intentionally left blank \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Improving Public Messaging for Evacuation and Shelter-in-Place \n",
      "Contributors \n",
      "• \n",
      "Carol Freeman, Argonne National Laboratory, National Preparedness Analytics Center1 \n",
      "• \n",
      "Nicole Nunn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # Ensure PyMuPDF is installed: pip install pymupdf\n",
    "\n",
    "folder_path = \"data\"  # Replace with your folder name\n",
    "documents = load_pdfs_from_folder(folder_path)\n",
    "\n",
    "print(f\"{len(documents)} PDFs loaded and extracted.\")\n",
    "print(\"Preview of first document:\")\n",
    "print(documents[0][:500])  # Print the first 500 characters of the first PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 chunks created.\n",
      "Preview of first chunk:\n",
      " Improving Public Messaging for Evacuation and Shelter‐in‐Place Findings and Recommendations for Emergency Managers from Peer-Reviewed Research April 2021 Improving Public Messaging for Evacuation and Shelter-in-Place This page intentionally left blank Improving Public Messaging for Evacuation and Shelter-in-Place Contributors • Carol Freeman, Argon\n"
     ]
    }
   ],
   "source": [
    "def split_into_chunks(documents, chunk_size=300, overlap=50):\n",
    "    chunks = []\n",
    "    for doc in documents:\n",
    "        words = doc.split()\n",
    "        start = 0\n",
    "        while start < len(words):\n",
    "            end = start + chunk_size\n",
    "            chunk = \" \".join(words[start:end])\n",
    "            chunks.append(chunk)\n",
    "            start += chunk_size - overlap  # overlap improves context in retrieval\n",
    "    return chunks\n",
    "\n",
    "chunks = split_into_chunks(documents, chunk_size=300, overlap=50)\n",
    "print(f\"{len(chunks)} chunks created.\")\n",
    "print(\"Preview of first chunk:\\n\", chunks[0][:350])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45e9af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    # Chunks text (by characters) with overlap\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        if chunk.strip():  # Don't save empty chunks\n",
    "            chunks.append(chunk)\n",
    "        if end >= text_length:\n",
    "            break\n",
    "        start += chunk_size - chunk_overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea2fefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "preprocessed_chunks = [preprocess_text(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cdf2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Creates embeddings for the given text.\n",
    "\n",
    "    Args:\n",
    "    text (str or List[str]): The input text(s) for which embeddings are to be created.\n",
    "    model (str): The model to be used for creating embeddings.\n",
    "\n",
    "    Returns:\n",
    "    List[float] or List[List[float]]: The embedding vector(s).\n",
    "    \"\"\"\n",
    "    # Handle both string and list inputs by converting string input to a list\n",
    "    input_text = text if isinstance(text, list) else [text]\n",
    "    \n",
    "    # Create embeddings for the input text using the specified model\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text\n",
    "    )\n",
    "    \n",
    "    # If the input was a single string, return just the first embedding\n",
    "    if isinstance(text, str):\n",
    "        return response.data[0].embedding\n",
    "    \n",
    "    # Otherwise, return all embeddings for the list of texts\n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb672989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    def __init__(self):\n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        query_vec = np.array(query_embedding)\n",
    "        similarities = []\n",
    "        for i, vec in enumerate(self.vectors):\n",
    "            sim = np.dot(query_vec, vec) / (np.linalg.norm(query_vec) * np.linalg.norm(vec))\n",
    "            similarities.append((i, sim))\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        results = []\n",
    "        for idx, score in similarities[:k]:\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": score\n",
    "            })\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0cd0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9254db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, chunk_size=1000, chunk_overlap=200):\n",
    "    store = SimpleVectorStore()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing: {filename}\")\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            chunks = chunk_text(text, chunk_size, chunk_overlap)\n",
    "            preprocessed = [preprocess_text(chunk) for chunk in chunks]\n",
    "            if not preprocessed:\n",
    "                continue\n",
    "            embeddings = create_embeddings(preprocessed)\n",
    "            for i, (chunk, embedding) in enumerate(zip(preprocessed, embeddings)):\n",
    "                store.add_item(\n",
    "                    text=chunk,\n",
    "                    embedding=embedding,\n",
    "                    metadata={\"source\": filename, \"chunk_index\": i}\n",
    "                )\n",
    "    print(f\"Total chunks in vector store: {len(store.texts)}\")\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eeafef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(store, question, k=3):\n",
    "    query_embedding = create_embeddings(question)\n",
    "    hits = store.similarity_search(query_embedding, k=k)\n",
    "    print(f\"\\nTop {k} results for: \\\"{question}\\\"\")\n",
    "    for i, item in enumerate(hits):\n",
    "        print(f\"\\nResult {i+1} [source: {item['metadata']['source']}, similarity: {item['similarity']:.3f}]\")\n",
    "        print(item[\"text\"][:500], \"...\")  # Preview chunk\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d09a261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: fema_improving-public-messaging-for-evacuation-and-shelter-in-place_literature-review-report.pdf\n",
      "Processing: fema_national-resilience-guidance_august2024.pdf\n",
      "Processing: fema_npd_developing-and-maintaining-emergency_052125.pdf\n",
      "Processing: fema_npd_local-elected-officials-quick-reference-guide_2025.pdf\n",
      "Processing: fema_pdhi-final-report-letter-amended.pdf\n",
      "Processing: fema_shelter-in-place_guidance.pdf\n",
      "Total chunks in vector store: 826\n",
      "\n",
      "Top 3 results for: \"What are the recommended steps for evacuation according to FEMA?\"\n",
      "\n",
      "Result 1 [source: fema_improving-public-messaging-for-evacuation-and-shelter-in-place_literature-review-report.pdf, similarity: 0.649]\n",
      "who take the appropriate protective action to evacuate or to sip. many of these research findings are likely to be familiar to emergency managers with experience in evacuation operations. key recommendations include: 1. understand the potential impediments to action and take steps to address these barriers in advance. 2. make evacuation decisions easier by only issuing mandatory evacuation orders. 3. provide residents and tourists with multiple ways to know if they are in a zone under an evacuat ...\n",
      "\n",
      "Result 2 [source: fema_improving-public-messaging-for-evacuation-and-shelter-in-place_literature-review-report.pdf, similarity: 0.646]\n",
      "ty but that should not stop them from evacuating. if relevant, note steps that government is taking to keep property secure until individuals can return to their community, such as increased patrols, curfews, etc. 3.8 • • those living in manufactured or mobile homes: • because this type of housing is structurally less safe, encourage those individuals to evacuate early and plan to provide services to those who may need assistance. 3.8 • • individuals who need assistance: ensure messaging include ...\n",
      "\n",
      "Result 3 [source: fema_npd_developing-and-maintaining-emergency_052125.pdf, similarity: 0.594]\n",
      "escribe how to keep children and others with disabilities or access and functional needs with their caregivers, mobility devices, other durable medical equipment and/or service animals during an evacuation.  identify and describe how to exchange registration and tracking information between and among the evacuating jurisdiction, the receiving jurisdiction(s) and the jurisdictions that evacuees pass through.  describe the coordination strategies for managing and possibly relocating incarcerated ...\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"data\"\n",
    "store = process_folder(folder_path)\n",
    "question = \"What are the recommended steps for evacuation according to FEMA?\"\n",
    "results = answer_query(store, question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea1221bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Answer:\n",
      " The recommended steps for evacuation according to FEMA include:\n",
      "\n",
      "1. **Understand potential impediments**: Identify and address barriers to action in advance.\n",
      "2. **Simplify evacuation decisions**: Issue only mandatory evacuation orders to make decisions easier.\n",
      "3. **Provide information**: Ensure residents and tourists have multiple ways to know if they are in an evacuation zone.\n",
      "4. **Use multiple messaging channels**: Utilize authoritative channels that include visual information about the hazard and encourage sharing.\n",
      "5. **Frequent updates**: Provide regular updates to reduce stress related to the unknown aspects of evacuation.\n",
      "6. **Encourage early evacuation for vulnerable populations**: Specifically advise those in manufactured or mobile homes to evacuate early and plan for assistance.\n",
      "7. **Assist individuals with disabilities**: Ensure messaging includes information on support for transportation and evacuation planning for those with disabilities or access needs.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "context = \"\\n\\n\".join([item['text'] for item in results])\n",
    "llm_prompt = (\n",
    "    f\"Answer the following question using ONLY the provided context. Cite specific steps or guidance mentioned.\\n\"\n",
    "    f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "response = openai.OpenAI().chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or \"gpt-3.5-turbo\", etc.\n",
    "    messages=[{\"role\": \"user\", \"content\": llm_prompt}],\n",
    "    max_tokens=512,\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(\"LLM Answer:\\n\", response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
